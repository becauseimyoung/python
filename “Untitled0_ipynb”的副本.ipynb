{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“Untitled0.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/becauseimyoung/python/blob/master/%E2%80%9CUntitled0_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YWv9rEhEx5Ag",
        "colab_type": "code",
        "outputId": "9e267ad5-89ca-4d1c-ab8e-a03dd81c354b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Oct 24 09:48:06 2018\n",
        "@author: Leon\n",
        "内容：\n",
        "以LeNet-5网络为模型，搭建CNN，对mnist手写数字进行训练及测试\n",
        "给关键tensor添加name，方便保存模型后的调用\n",
        "\"\"\"\n",
        " \n",
        "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
        "import tensorflow as tf\n",
        "import time\n",
        "tf.reset_default_graph()#如果保存模型时报错，应清除已有图\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
        " \n",
        "x = tf.placeholder(tf.float32,[None,784],name='x')\n",
        "y = tf.placeholder(tf.float32,[None,10],name='y')\n",
        " \n",
        "def weight_variable(shape,name):  \n",
        "    initial = tf.truncated_normal(shape, stddev = 0.1,name=name) # 截断正态分布  \n",
        "    return tf.Variable(initial)  \n",
        "  \n",
        "def bias_variable(shape,name):  \n",
        "    initial = tf.constant(0.1, shape=shape, name=name) # 常量0.1  \n",
        "    return tf.Variable(initial)\n",
        " \n",
        "# =============================================================================\n",
        "#  第一层：卷积+激活+池化\n",
        "# =============================================================================\n",
        "# 卷积核5*5,通道为1，个数为32个\n",
        "filter1 = weight_variable([5,5,1,32],name='filter1')\n",
        "# 卷积层：步长1*1,\n",
        "# Padding 有两个参数：\n",
        "# SAME——输出大小为:输入大小/s；\n",
        "# VALID——输出大小为：(输入大小-f+1)/s\n",
        "x_img = tf.reshape(x,[-1,28,28,1],name='x_img')\n",
        "conv1 = tf.nn.conv2d(x_img, filter1, strides=[1,1,1,1], padding='SAME',name='conv1')\n",
        "# 激活层：加偏移，然后激活\n",
        "bias1 = bias_variable([32],name='bias1')\n",
        "relu1 = tf.nn.relu(conv1+bias1,name='relu1')\n",
        "# 池化层：窗口大小2*2，步长2*2\n",
        "pool1 = tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name='pool1')\n",
        "print(\"第一层输出尺寸：\",pool1.shape)\n",
        " \n",
        "# =============================================================================\n",
        "# 第二层：卷积+激活+池化\n",
        "# =============================================================================\n",
        "# 卷积核大小5*5,1通道，64个卷积核\n",
        "filter2 = weight_variable([5,5,32,64],name='filter2')\n",
        "# 卷积层：步长1*1\n",
        "conv2 = tf.nn.conv2d(pool1,filter2,strides=[1,1,1,1],padding='SAME',name='conv2')\n",
        "# 激活层：加偏移，然后激活\n",
        "bias2 = bias_variable([64],name='bias2')\n",
        "relu2 = tf.nn.relu(conv2+bias2,name='relu2')\n",
        "# 池化层：\n",
        "pool2 = tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name='pool2')\n",
        "print(\"第二层输出尺寸：\", pool2.shape)\n",
        " \n",
        "# =============================================================================\n",
        "# 第三层：全连接层\n",
        "# =============================================================================\n",
        "# 提取上一层输出的尺寸\n",
        "shape = pool2.shape.as_list()\n",
        "# 拉伸上层输出，构造本层输入\n",
        "fc_input = tf.reshape(pool2,[-1,shape[1]*shape[2]*shape[3]])\n",
        "# 全连接层的权重：大小为本层输入*本层神经元的个数，也即下面的：[shape[1]*shape[2]*shape[3],32]\n",
        "fc_w = weight_variable([shape[1]*shape[2]*shape[3],1024], name='fc_w')\n",
        "# 全连接层的偏移量：大小为本层神经元的个数——32\n",
        "fc_b = bias_variable([1024],name='fc_b')\n",
        "# 建立本层全连接结构，并激活\n",
        "fc_out = tf.nn.relu(tf.matmul(fc_input,fc_w)+fc_b,name='fc_out')\n",
        "print(\"第三层输出尺寸：\", fc_out.shape)\n",
        " \n",
        "# Dropout，用来防止过拟合  \n",
        "# 加在输出层之前，训练过程中开启dropout，测试过程中关闭  \n",
        "keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
        "fc_out_drop = tf.nn.dropout(fc_out, keep_prob,name='fc_out_drop')\n",
        " \n",
        "# =============================================================================\n",
        "# 输出层\n",
        "# =============================================================================\n",
        "out_w = weight_variable([1024,10],name='out_w')\n",
        "out_b = bias_variable([10],name='out_b')\n",
        "pred = tf.nn.softmax(tf.matmul(fc_out_drop,out_w)+out_b,name='pred')\n",
        " \n",
        "# 定义损失函数\n",
        "loss = -tf.reduce_sum(y*tf.log(pred),name='loss')\n",
        "# 定义优化器：Adam优化函数\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001,name='optimizer').minimize(loss)\n",
        " \n",
        "# 定义评价指标——准确率\n",
        "bool_pred = tf.equal(tf.arg_max(y,1), tf.arg_max(pred,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(bool_pred,tf.float32),name='accuracy')\n",
        " \n",
        "# 定义全局变量初始化\n",
        "init = tf.global_variables_initializer()\n",
        " \n",
        "# 定义保存模型类\n",
        "saver = tf.train.Saver()\n",
        " \n",
        "# 启动图\n",
        "with tf.Session() as sess:\n",
        "    # 执行是初始化\n",
        "    sess.run(init)\n",
        "    # 训练样本中，总的batch个数\n",
        "    total_batch_nums = int(mnist.train.num_examples/50)\n",
        "    for epoch in range(1):\n",
        "        avg_loss = 0.\n",
        "        time_start = time.clock()\n",
        "        for i in range(total_batch_nums):\n",
        "            \n",
        "            batch = mnist.train.next_batch(50)\n",
        "            batch_xs,batch_ys = batch\n",
        "#            batch_xs = batch_xs.reshape([-1,28,28,1])\n",
        "            sess.run(optimizer,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.5})\n",
        "#            avg_loss += sess.run(loss, feed_dict={x:batch_xs,y:batch_ys})\n",
        "        time_end = time.clock()\n",
        "        \n",
        "        if epoch %1 == 0:\n",
        "            accuracy_eval = sess.run(accuracy, \n",
        "                                     feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
        "            print(\"Epoch:\",\"%04d\"%(epoch+1),\n",
        "#                  \"loss:\",\"%.4f\"%avg_loss,\n",
        "                  \"accuracy:\",accuracy_eval,\n",
        "                  \"running time:\",\"%g\"%(time_end-time_start))\n",
        "            \n",
        "    saver.save(sess,'model/my_model')\n",
        "    accuracy_test = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
        "    print(\"test accuracy:\",accuracy_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-7717c3304fb0>:13: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "第一层输出尺寸： (?, 14, 14, 32)\n",
            "第二层输出尺寸： (?, 7, 7, 64)\n",
            "第三层输出尺寸： (?, 1024)\n",
            "WARNING:tensorflow:From <ipython-input-1-7717c3304fb0>:91: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `argmax` instead\n",
            "Epoch: 0001 accuracy: 1.0 running time: 9.83624\n",
            "test accuracy: 0.9845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eBxIic_y00zH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwC9yHGA01oW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}